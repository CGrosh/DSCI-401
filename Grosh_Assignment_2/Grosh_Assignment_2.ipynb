{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Regression Modeling and Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis and Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sale.Condition\n",
      "Abnorml    142501.932099\n",
      "AdjLand    113300.000000\n",
      "Alloca     162899.850000\n",
      "Family     162082.857143\n",
      "Normal     174771.834982\n",
      "Partial    276710.954082\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import the necesary libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import  RFECV\n",
    "import functools \n",
    "from util import *\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Read in the training data \n",
    "df = pd.read_csv('Datasets/AmesHousingSetA.csv')\n",
    "\n",
    "# Manually Encode the Central Air Feature \n",
    "df['Central.Air'] = df['Central.Air'].replace(to_replace='Y', value=1)\n",
    "df['Central.Air'] = df['Central.Air'].replace(to_replace='N', value=0)\n",
    "\n",
    "# Get Rid of Features that had a significant amount of null values \n",
    "del df['Alley']\n",
    "del df['Pool.QC']\n",
    "del df['Misc.Feature']\n",
    "del df['Fireplace.Qu']\n",
    "del df['Fence']\n",
    "\n",
    "# PID is an ID column so it doed not make sense that it would have any effect on the SalePrice\n",
    "# This can be seen in the scatter plot, there is no relationship between Sale Price and PID \n",
    "df.plot(kind='scatter', x='SalePrice', y= 'Lot.Area')\n",
    "plt.show()\n",
    "del df['PID']\n",
    "\n",
    "# Grouping Sale.Condition and Sale Price to see which kind of Sale.Condition\n",
    "# Has the higher average price \n",
    "print(df.groupby('Sale.Condition')['SalePrice'].mean())\n",
    "\n",
    "# Call the cat_features function and make a list of all the Non-Numeric Features \n",
    "x = list(cat_features(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a Preprocessing Pipeline and One-Hot Encode the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the Imputation to Fill in the NaN values with the median \n",
    "imp = preprocessing.Imputer(missing_values = 'NaN', strategy='mean', axis=0)\n",
    "\n",
    "# Declare the Scaler to Standardize the columns with their z-scores \n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# One Hot Encode the Categorical Columns \n",
    "df_dum = pd.get_dummies(df, columns = x)\n",
    "\n",
    "# Segment the Independent and Dependent Variables \n",
    "base_data_x = df_dum.loc[:, df_dum.columns != 'SalePrice']\n",
    "base_data_y = df_dum['SalePrice']\n",
    "\n",
    "# Split into Training and Testing Set \n",
    "x_train, x_test, y_train, y_test = train_test_split(base_data_x, base_data_y, test_size=0.2, random_state = 4)\n",
    "\n",
    "# Pass the Training Independent Variables through the Preprocessin Pipeline \n",
    "train_x_pp = imp.fit_transform(x_train)\n",
    "train_x_pp = scaler.fit_transform(train_x_pp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Data on the Base model: A Simple Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE, MAE, R^2, EVS: [5.516768280330365e+32, 1907552652192646.2, -8.138226733864242e+22, -8.138226733864244e+22]\n"
     ]
    }
   ],
   "source": [
    "# Declare the Base Linear Model and fit on the Training Data \n",
    "base_model = linear_model.LinearRegression()\n",
    "base_model.fit(train_x_pp, y_train)\n",
    "\n",
    "# Run the Testing data through the Preprocessing Pipeline\n",
    "test_x_pp = imp.fit_transform(x_test)\n",
    "test_x_pp = scaler.fit_transform(test_x_pp)\n",
    "\n",
    "# Make Predictions on the testing data \n",
    "base_preds = base_model.predict(test_x_pp)\n",
    "\n",
    "print('MSE, MAE, R^2, EVS: ' + str([mean_squared_error(y_test, base_preds),\n",
    "                                    median_absolute_error(y_test, base_preds),\n",
    "                                    r2_score(y_test, base_preds),\n",
    "                                    explained_variance_score(y_test, base_preds)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Best Model: Start with Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ColinG/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/ColinG/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/ColinG/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/ColinG/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "# Construct a Dictionary to store the F test P-Value for each coulmn \n",
    "feat_val = {}\n",
    "selector_f = SelectPercentile(f_regression, percentile=25)\n",
    "selector_f.fit(train_x_pp, y_train)\n",
    "for name, score, pv in zip(list(df_dum), selector_f.scores_, selector_f.pvalues_):\n",
    "    feat_val[name] = pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all the features that have a p-value of 0.04 or less \n",
    "FeatSel = ['SalePrice']\n",
    "for i in feat_val:\n",
    "    if feat_val[i] < 0.04:\n",
    "        FeatSel.append(i)\n",
    "\n",
    "# New Dataframe with the specially selected Features \n",
    "FeatSel_df = df_dum[FeatSel]\n",
    "\n",
    "# Segment the Independent and Dependent Variables \n",
    "data_x = FeatSel_df.loc[:, FeatSel_df.columns != 'SalePrice']\n",
    "data_y = FeatSel_df['SalePrice']\n",
    "\n",
    "# Split into Training and Testing Set \n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state = 4)\n",
    "\n",
    "# Pass the Training Independent Variables through the Preprocessing Pipeline \n",
    "train_x_pp = imp.fit_transform(x_train)\n",
    "train_x_pp = scaler.fit_transform(train_x_pp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_pp = imp.fit_transform(x_test)\n",
    "test_x_pp = scaler.fit_transform(test_x_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a Couple Different Models to see what fits best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ColinG/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R^2 for the Lasso Model is: 0.9018243236257353\n",
      "The R^2 for the Ridge Model is: 0.901331714541974\n",
      "The R^2 for the Quadratic Model is: -117198752739959.61\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression Model \n",
    "Lasso_test = linear_model.Lasso(alpha=0.5, normalize = True)\n",
    "Lasso_test.fit(train_x_pp, y_train)\n",
    "Lasso_preds = Lasso_test.predict(test_x_pp)\n",
    "\n",
    "# Ridge Regression Model \n",
    "Ridge_test = linear_model.Ridge(alpha = 0.5)\n",
    "Ridge_test.fit(train_x_pp, y_train)\n",
    "Ridge_preds = Ridge_test.predict(test_x_pp)\n",
    "\n",
    "# Quadratic Regression Model \n",
    "Quad_test = PolynomialFeatures(degree=2)\n",
    "Quad_Data_x_train = Quad_test.fit_transform(train_x_pp)\n",
    "Quad_Data_x_test = Quad_test.fit_transform(test_x_pp)\n",
    "Quad_mod = linear_model.LinearRegression()\n",
    "Quad_mod.fit(Quad_Data_x_train, y_train)\n",
    "quad_preds = Quad_mod.predict(Quad_Data_x_test)\n",
    "\n",
    "print(\"The R^2 for the Lasso Model is: \" + str(r2_score(y_test, Lasso_preds)))\n",
    "print('The R^2 for the Ridge Model is: ' + str(r2_score(y_test, Ridge_preds)))\n",
    "print(\"The R^2 for the Quadratic Model is: \" + str(r2_score(y_test, quad_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Different Alpha Levels for the Lasso Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ColinG/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  import sys\n",
      "/Users/ColinG/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/ColinG/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 (Lasso model with alpha =0.0):0.9008271357206838\n",
      "R^2 (Lasso model with alpha =0.001):0.9008298406250516\n",
      "R^2 (Lasso model with alpha =0.01):0.9008515372781289\n",
      "R^2 (Lasso model with alpha =0.1):0.9011066267259815\n",
      "R^2 (Lasso model with alpha =0.25):0.9014188184317952\n",
      "R^2 (Lasso model with alpha =0.5):0.9018243236257353\n",
      "R^2 (Lasso model with alpha =1.0):0.902349224190156\n",
      "R^2 (Lasso model with alpha =2.5):0.9032311053170106\n",
      "R^2 (Lasso model with alpha =5.0):0.9029248838948771\n"
     ]
    }
   ],
   "source": [
    "# List of different possible alpha levels for the Ridge Regression \n",
    "alphas = [0.0, 0.001, 0.01, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0]\n",
    "\n",
    "# Loop through the alphas and build  Lasso Model with each and Check the R^2\n",
    "for alpha in alphas: \n",
    "    model = linear_model.Lasso(alpha = alpha, normalize=True)\n",
    "    model.fit(train_x_pp, y_train)\n",
    "    preds = model.predict(test_x_pp)\n",
    "    print('R^2 (Lasso model with alpha =' + str(alpha) + '):' + str(r2_score(y_test, preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the specially selected features and the best alpha level to build that Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for Best model: 0.9032311053170106\n"
     ]
    }
   ],
   "source": [
    "# Based on the tested alpha levels we can see that the R^2 begins to drop off at around 2.5 \n",
    "\n",
    "# Build the Best Lasso Model using alpha of 2.5 \n",
    "best_model = linear_model.Lasso(alpha = 2.5, normalize=True)\n",
    "\n",
    "# Fit it with the preprocessed testing data \n",
    "best_model.fit(train_x_pp,  y_train)\n",
    "\n",
    "# Make predictions using the preprocesed testing data \n",
    "best_preds = best_model.predict(test_x_pp)\n",
    "\n",
    "# R^2 value for the Best model on the Testing set \n",
    "print(\"R^2 for Best model: \" + str(r2_score(y_test, best_preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the B Dataset and perform the Necesary transformations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from the B Set \n",
    "df_b = pd.read_csv('Datasets/AmesHousingSetB.csv')\n",
    "df_b['Central.Air'] = df_b['Central.Air'].replace(to_replace='Y', value=1)\n",
    "df_b['Central.Air'] = df_b['Central.Air'].replace(to_replace='N', value=0)\n",
    "\n",
    "# Get Rid of Features that had a significant amount of null values or were insignificant \n",
    "del df_b['Alley']\n",
    "del df_b['Pool.QC']\n",
    "del df_b['Misc.Feature']\n",
    "del df_b['Fireplace.Qu']\n",
    "del df_b['Fence']\n",
    "del df_b['PID']\n",
    "\n",
    "# List of the Categorical Features \n",
    "x_b = list(cat_features(df_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Base and Best Models with the Transformed Data from Dataset B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for the Base model on the B Dataset is: -7.212398132165294e+23\n"
     ]
    }
   ],
   "source": [
    "# One Hot encode the B Dataset \n",
    "df_dum_b = pd.get_dummies(df_b, columns = x_b)\n",
    "\n",
    "# Loop Through and check what columns are in B but not in A, and then delete them \n",
    "for i in df_dum_b.columns:\n",
    "    if i not in df_dum.columns:\n",
    "        del df_dum_b[i]\n",
    "        \n",
    "# Loop through and check what columns are in A but not in B, and then add them \n",
    "for i in df_dum.columns:\n",
    "    if i not in df_dum_b.columns:\n",
    "        df_dum_b[i] = pd.Series(np.zeros(len(df_dum_b)))\n",
    "\n",
    "# Segment the data \n",
    "dataB_x = df_dum_b.loc[:, df_dum_b.columns != 'SalePrice']\n",
    "dataB_y = df_dum_b['SalePrice']\n",
    "\n",
    "\n",
    "# Pass the Independent Variables through the Preprocessin Pipeline \n",
    "dataB_x_pp = imp.fit_transform(dataB_x)\n",
    "dataB_x_pp = scaler.fit_transform(dataB_x_pp)\n",
    "\n",
    "# Make the predictions on the data \n",
    "B_base_preds = base_model.predict(dataB_x_pp)\n",
    "\n",
    "# Compute the R^2 of the model \n",
    "print(\"R^2 for the Base model on the B Dataset is: \" + str(r2_score(dataB_y, B_base_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for the Best Model on the B Dataset is: 0.9130786140451412\n"
     ]
    }
   ],
   "source": [
    "# Segment the Feature Selected Data for Best Model \n",
    "dataB_best = df_dum_b[FeatSel]\n",
    "\n",
    "# Seperate into X and Y \n",
    "dataB_x_best = dataB_best.loc[:, dataB_best.columns != 'SalePrice']\n",
    "dataB_y_best = dataB_best['SalePrice']\n",
    "\n",
    "# Send the data through the Preproccesing Pipeline \n",
    "dataB_x_best_pp = imp.fit_transform(dataB_x_best)\n",
    "dataB_x_best_pp = scaler.fit_transform(dataB_x_best_pp)\n",
    "\n",
    "# Make Predictions on the B Dataset \n",
    "best_preds_B = best_model.predict(dataB_x_best_pp)\n",
    "\n",
    "# Print the R^2 for the data \n",
    "print(\"R^2 for the Best Model on the B Dataset is: \" + str(r2_score(best_preds_B, dataB_y_best)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data Preparation Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) \n",
    "\n",
    "## To transform the data, I one hot encoded all the categorical columns. For the Central.Air column, I manually changed the values from \"Y\" to 1, and from \"N\" to 0. This one-hot encoding made the 81 column data frame a 300 column dataframe.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Exploratory Analysis Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) \n",
    "\n",
    "## When looking at the data, there were a few columns that had a significant amount of NaN values. For examples    only had 9 non-NaN values. For this column and the 4 other columns similar to it I removed them, as they would not be good predictors due to having barely any data. \n",
    "\n",
    "## Also, I removed the PID column because it was simply an ID column. It is a unqiue value for each of the rows that has no bearing on the SalePrice. I checked this with a scatter plot on sale price and it as expected showed no relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) \n",
    "\n",
    "## I expected fr Lot.Area to have a positive effect on Sale Price. I was surprised when looking at the scatter plot and seeing what looked like not correlation at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Model Building Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) \n",
    "\n",
    "## To arrive at my most accurate model, I used  Lasso Regression Model. I had learned in my DATA 419 class that Lasso was on average the most accurate when compare to basic linear and ridge regression so I decided to test with Lasso first. To confirm this, built 3 models to test, a Lasso Model, a Ridge model, and a Quadratic model. \n",
    "\n",
    "## After fitting and predicting with each of these models, the R^2 for the Lasso and Ridge regression models were very close, with the Lasso being higher by about a percent. The Quadratic was a very poor fit so that was ignored. \n",
    "\n",
    "## Finally, I featured selcted by running an F-Test on every explanatory column and then only including the columns that had a p-value of 0.04 or less. This allowed me to get rid of columns not as important and keep the ones with real signifigance in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) \n",
    "\n",
    "## The Primary error metrics used to evaluate the Base and Best model was the R^2 value. The R^2 for the base Linear model was incredibly small, at about , meanwhile with the Best model the R^2 sat right around 90%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Predicting and Validating Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) \n",
    "\n",
    "## My Best Model once again greatly outscored my baseline model on the B dataset. The Base model had a -7.212 x 10^23 R^2. The Best model had a very accuracte R^2 of 0.913. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) \n",
    "\n",
    "## The Best Model is a very good model, however it does require a decent amount of transformation of the data, and ignores certain columns that originally had too many null values. Therefore new with less null values could effect the accuracy of the model. \n",
    "\n",
    "## Another issue with the model is probably with misunderstanding the column names. It was difficult to understand what some of the columns actually represented, so therefore some untrue assumptions could have been made that would influence feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
