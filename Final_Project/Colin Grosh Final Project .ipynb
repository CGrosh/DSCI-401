{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ColinG/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary Libraries \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Read in the data \n",
    "data = pd.read_csv('kickstarter_projects_data/ks-projects-201612.csv', \n",
    "                   delimiter = ',', encoding='ISO-8859-1')\n",
    "\n",
    "# Delete unnecessary columns \n",
    "del data['Unnamed: 13']\n",
    "del data['Unnamed: 14']\n",
    "del data['Unnamed: 15']\n",
    "del data['Unnamed: 16']\n",
    "del data['currency ']\n",
    "del data['category ']\n",
    "del data['name ']\n",
    "del data['ID ']\n",
    "del data['usd pledged ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segement the Date string from the Launch and Deadline columns \n",
    "diff = []\n",
    "launch = []\n",
    "dead = []\n",
    "for i in range(len(data)):\n",
    "    launch.append(data['launched '][i].split(' ')[0])\n",
    "    dead.append(data['deadline '][i].split(' ')[0])\n",
    "launch = pd.Series(launch)\n",
    "dead = pd.Series(dead)\n",
    "\n",
    "# Convert the the Launch and deadline columns into datetime objects \n",
    "launch = pd.to_datetime(launch, format='%m/%d/%y', errors='coerce')\n",
    "dead = pd.to_datetime(dead, format='%m/%d/%y', errors='coerce')\n",
    "data['launch'] = launch\n",
    "data['dead'] = dead\n",
    "\n",
    "# Loop through and get the total number of days that the project was live on Kickstarter \n",
    "for i in range(len(data)):\n",
    "    diff.append((data['dead'][i] - data['launch'][i]).days)\n",
    "    \n",
    "# Create a new column of the number of days \n",
    "diff = pd.Series(diff)\n",
    "data['Length'] = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to re-Format\n"
     ]
    }
   ],
   "source": [
    "# Check if the row is not aligned with the columns and drop those indexes \n",
    "check = ['failed', 'successful', 'canceled', 'live', 'undefined', 'suspended']\n",
    "count = []\n",
    "for i in range(len(data)):\n",
    "    if data['state '][i].isdigit() == True:\n",
    "        count.append(i)\n",
    "    elif data['state '][i] not in check:\n",
    "        count.append(i)\n",
    "data = data.drop(data.index[count])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Check if the amount donated is larger than the amount requested and then label it \n",
    "# as either successful or failed\n",
    "data['goal '] = data['goal '].astype('float32')\n",
    "data['pledged '] = data['pledged '].astype('float32')\n",
    "data['Diff'] = data['goal ']-data['pledged ']\n",
    "data['backers '] = data['backers '].astype('int64')\n",
    "\n",
    "data['goal '] = data['goal '].astype('int64')\n",
    "data['pledged '] = data['pledged '].astype('int64')\n",
    "print(\"Preparing to re-Format\")\n",
    "\n",
    "prep=[]\n",
    "for i in range(len(data)):\n",
    "  if data['Diff'][i] <= 0:\n",
    "    prep.append('successful')\n",
    "  else: \n",
    "    prep.append('failure')\n",
    "\n",
    "data['result'] = pd.Series(prep)\n",
    "\n",
    "# Remove severly extreme outliers \n",
    "data = data[data['Length'] < 3000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the columns and remove all non-predictor columns\n",
    "lst = list(data.columns)\n",
    "lst.remove('launched ')\n",
    "lst.remove('deadline ')\n",
    "lst.remove('state ')\n",
    "lst.remove('dead')\n",
    "lst.remove('launch')\n",
    "lst.remove('Diff')\n",
    "lst.remove('result')\n",
    "lst.remove('pledged ')\n",
    "\n",
    "# Function to determine which of our predictors are categorical \n",
    "def cat_features(dataframe):\n",
    "    td = pd.DataFrame({'a': [1,2,3], 'b': [1.0, 2.0, 3.0]})\n",
    "    return filter(lambda x: not(dataframe[x].dtype in [td['a'].dtype, \n",
    "                                          td['b'].dtype]), list(dataframe))\n",
    "\n",
    "# Specify the x and the y variables and One-hot encode the categorical predictors \n",
    "data_x = data[lst]\n",
    "data_x = pd.get_dummies(data_x, columns=list(cat_features(data_x[lst])))\n",
    "data_y = data['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Train Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ColinG/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Build the Label Encoding Pipeline for the Target Variable \n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Build the Imputer Pipeline to fill NaN values \n",
    "imp = preprocessing.Imputer(missing_values = 'NaN', strategy = 'mean', axis=0)\n",
    "\n",
    "# Build the Scaler Pipeline for the Predictors \n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Pass the Target Variable through the Label Encoding Pipeline \n",
    "data_y = le.fit_transform(data_y)\n",
    "\n",
    "# Split the data into Training and Testing Sets \n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, \n",
    "                                                    test_size=0.2, random_state=4)\n",
    "\n",
    "# Pass the training Predictors through the Preprocessing Pipeline \n",
    "train_x_pp = imp.fit_transform(x_train)\n",
    "train_x_pp = scaler.fit_transform(train_x_pp)\n",
    "\n",
    "# Pass the testing Predictors through the Preprocessing Pipeline \n",
    "test_x_pp = imp.fit_transform(x_test)\n",
    "test_x_pp = scaler.fit_transform(test_x_pp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Random Forest with Mulitiple Combinations of Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Random Forest Model with Multiple Combinations of Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Evaluating Model: n_estimators = 5, max_depth = 2 ------\n",
      "0.64342416786593\n",
      "0.03517146087174978\n",
      "-----Evaluating Model: n_estimators = 5, max_depth = 4 ------\n",
      "0.6645312040604738\n",
      "0.2001844678103671\n",
      "-----Evaluating Model: n_estimators = 5, max_depth = 6 ------\n",
      "0.8260371694288411\n",
      "0.7483322140138795\n",
      "-----Evaluating Model: n_estimators = 5, max_depth = 8 ------\n",
      "0.8616127384986769\n",
      "0.8253422651016542\n",
      "-----Evaluating Model: n_estimators = 10, max_depth = 2 ------\n",
      "0.6785974034012658\n",
      "0.2586908416018274\n",
      "-----Evaluating Model: n_estimators = 10, max_depth = 4 ------\n",
      "0.8113055723194528\n",
      "0.723880259046239\n",
      "-----Evaluating Model: n_estimators = 10, max_depth = 6 ------\n",
      "0.8469275644894233\n",
      "0.8063202412186239\n",
      "-----Evaluating Model: n_estimators = 10, max_depth = 8 ------\n",
      "0.8584869164229454\n",
      "0.8286073055081806\n",
      "-----Evaluating Model: n_estimators = 50, max_depth = 2 ------\n",
      "0.795103910372468\n",
      "0.6776384662203285\n",
      "-----Evaluating Model: n_estimators = 50, max_depth = 4 ------\n",
      "0.8431053959116723\n",
      "0.7974428129058037\n",
      "-----Evaluating Model: n_estimators = 50, max_depth = 6 ------\n",
      "0.8484285780604429\n",
      "0.8192704393232099\n",
      "-----Evaluating Model: n_estimators = 50, max_depth = 8 ------\n",
      "0.8506414125001934\n",
      "0.8219385307899495\n",
      "-----Evaluating Model: n_estimators = 100, max_depth = 2 ------\n",
      "0.665537037896724\n",
      "0.15259154708695993\n",
      "-----Evaluating Model: n_estimators = 100, max_depth = 4 ------\n",
      "0.8233601039877443\n",
      "0.7545952918413414\n",
      "-----Evaluating Model: n_estimators = 100, max_depth = 6 ------\n",
      "0.8564752487504449\n",
      "0.8253723193944985\n",
      "-----Evaluating Model: n_estimators = 100, max_depth = 8 ------\n",
      "0.8509818485678473\n",
      "0.8223706053786846\n"
     ]
    }
   ],
   "source": [
    "# Check error metrics for a Random Forest Model with different sets of hyper-parameters \n",
    "n_ests = [5,10,50,100]\n",
    "depths = [2,4,6,8]\n",
    "for n in n_ests:\n",
    "    for dp in depths:\n",
    "        mod = ensemble.RandomForestClassifier(n_estimators=n, max_depth=dp)\n",
    "        mod.fit(train_x_pp, y_train)\n",
    "        y_hat = mod.predict(test_x_pp)\n",
    "        print('-----Evaluating Model: n_estimators = ' + str(n) + ', max_depth = ' + str(dp) + ' ------')\n",
    "        print(accuracy_score(y_hat, y_test))\n",
    "        print(f1_score(y_hat, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the best Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Predicting took approximatly: 23.649368047714233\n",
      "------Random Forest Model With n_estimators = 50, and max_depth = 8---------\n",
      "Accuracy Score: 0.8472525261903656\n",
      "F1 Score: 0.8187643440741761\n"
     ]
    }
   ],
   "source": [
    "mod = ensemble.RandomForestClassifier(n_estimators=100, max_depth=8)\n",
    "start = time.time()\n",
    "mod.fit(train_x_pp, y_train)\n",
    "y_hat = mod.predict(test_x_pp)\n",
    "end = time.time()\n",
    "print(\"Training and Predicting took approximatly: \" + str(end-start))\n",
    "print(\"------Random Forest Model With n_estimators = 50, and max_depth = 8---------\")\n",
    "print(\"Accuracy Score: \" + str(accuracy_score(y_hat, y_test)))\n",
    "print(\"F1 Score: \" + str(f1_score(y_hat, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for a better Score by using K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score (F1 Macro for K-Fold): [0.89311409 0.89669826 0.89503929 0.89953726 0.89743909]\n",
      "Mean Score of The K-Fold CV: 0.8963655981259914\n",
      "K-Fold Training and Predicting took approximatly: 105.10018515586853\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=4) # This is 5-fold CV\n",
    "k_fold_scores = cross_val_score(mod, data_x, data_y, scoring='f1_macro', cv=k_fold)\n",
    "print('CV Score (F1 Macro for K-Fold): ' + str(k_fold_scores))\n",
    "print(\"Mean Score of The K-Fold CV: \" + str(k_fold_scores.mean()))\n",
    "end = time.time()\n",
    "print(\"K-Fold Training and Predicting took approximatly: \" + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and Clean the Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('kickstarter_projects_data/ks-projects-201801.csv', \n",
    "                   delimiter = ',', encoding='ISO-8859-1')\n",
    "\n",
    "del val_data['currency']\n",
    "del val_data['category']\n",
    "del val_data['name']\n",
    "del val_data['ID']\n",
    "del val_data['usd_pledged_real']\n",
    "del val_data['usd_goal_real']\n",
    "del val_data['usd pledged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segement the Date string from the Launch and Deadline columns \n",
    "diff = []\n",
    "launch = []\n",
    "dead = []\n",
    "for i in range(len(val_data)):\n",
    "    launch.append(val_data['launched'][i].split(' ')[0])\n",
    "    dead.append(val_data['deadline'][i])\n",
    "launch = pd.Series(launch)\n",
    "dead = pd.Series(dead)\n",
    "\n",
    "# Convert the the Launch and deadline columns into datetime objects \n",
    "launch = pd.to_datetime(launch, format='%Y/%m/%d', errors='coerce')\n",
    "dead = pd.to_datetime(dead, format='%Y/%m/%d', errors='coerce')\n",
    "val_data['launch'] = launch\n",
    "val_data['dead'] = dead\n",
    "\n",
    "# Loop through and get the total number of days that the project was live on Kickstarter \n",
    "for i in range(len(val_data)):\n",
    "    diff.append((val_data['dead'][i] - val_data['launch'][i]).days)\n",
    "    \n",
    "# Create a new column of the number of days \n",
    "diff = pd.Series(diff)\n",
    "val_data['Length'] = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to re-Format\n"
     ]
    }
   ],
   "source": [
    "# Check if the row is not aligned with the columns and drop those indexes \n",
    "check = ['failed', 'successful', 'canceled', 'live', 'undefined', 'suspended']\n",
    "count = []\n",
    "for i in range(len(val_data)):\n",
    "    if val_data['state'][i].isdigit() == True:\n",
    "        count.append(i)\n",
    "    elif val_data['state'][i] not in check:\n",
    "        count.append(i)\n",
    "if len(count) > 0:\n",
    "    val_data = val_data.drop(val_data.index[count])\n",
    "    val_data = val_data.reset_index(drop=True)\n",
    "\n",
    "# Check if the amount donated is larger than the amount requested and then label it \n",
    "# as either successful or failed\n",
    "val_data['goal '] = val_data['goal'].astype('float32')\n",
    "val_data['pledged '] = val_data['pledged'].astype('float32')\n",
    "val_data['Diff'] = val_data['goal']-val_data['pledged']\n",
    "val_data['backers '] = val_data['backers'].astype('int64')\n",
    "\n",
    "val_data['goal '] = val_data['goal '].astype('int64')\n",
    "val_data['pledged '] = val_data['pledged '].astype('int64')\n",
    "print(\"Preparing to re-Format\")\n",
    "\n",
    "prep=[]\n",
    "for i in range(len(val_data)):\n",
    "  if val_data['Diff'][i] <= 0:\n",
    "    prep.append('successful')\n",
    "  else: \n",
    "    prep.append('failure')\n",
    "\n",
    "val_data['result'] = pd.Series(prep)\n",
    "val_data['main_category '] = val_data['main_category']\n",
    "val_data['country '] = val_data['country']\n",
    "del val_data['main_category']\n",
    "del val_data['country']\n",
    "\n",
    "# Remove severly extreme outliers \n",
    "val_data = val_data[val_data['Length'] < 3000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the columns and remove all non-predictor columns\n",
    "val_lst = list(val_data.columns)\n",
    "val_lst.remove('launched')\n",
    "val_lst.remove('deadline')\n",
    "val_lst.remove('state')\n",
    "val_lst.remove('dead')\n",
    "val_lst.remove('launch')\n",
    "val_lst.remove('Diff')\n",
    "val_lst.remove('result')\n",
    "val_lst.remove('pledged')\n",
    "val_lst.remove('goal')\n",
    "val_lst.remove('pledged ')\n",
    "val_lst.remove('backers')\n",
    "\n",
    "# Function to determine which of our predictors are categorical \n",
    "def cat_features(dataframe):\n",
    "    td = pd.DataFrame({'a': [1,2,3], 'b': [1.0, 2.0, 3.0]})\n",
    "    return filter(lambda x: not(dataframe[x].dtype in [td['a'].dtype, \n",
    "                                          td['b'].dtype]), list(dataframe))\n",
    "\n",
    "# Specify the x and the y variables and One-hot encode the categorical predictors \n",
    "val_data_x = val_data[val_lst]\n",
    "val_data_x = pd.get_dummies(val_data_x, columns=list(cat_features(val_data_x[val_lst])))\n",
    "val_data_y = val_data['result']\n",
    "\n",
    "# Change names that do not match up with the \n",
    "val_data_x['country _N,\"0'] = val_data_x['country _N,0\"'] \n",
    "del val_data_x['country _N,0\"']\n",
    "del val_data_x['country _JP']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Validation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the Target Variable through the Label Encoding Pipeline \n",
    "val_data_y = le.fit_transform(val_data_y)\n",
    "\n",
    "# Pass the training Predictors through the Preprocessing Pipeline \n",
    "val_x_pp = imp.transform(val_data_x)\n",
    "val_x_pp = scaler.transform(val_x_pp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on the Validation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Random Forest Model With n_estimators = 50, and max_depth = 8---------\n",
      "Accuracy Score: 0.36102087921955134\n",
      "F1 Score: 0.530358085654834\n"
     ]
    }
   ],
   "source": [
    "# Make Predictions with the Random Forest Model \n",
    "val_y_hat = mod.predict(val_x_pp)\n",
    "\n",
    "# View Random Forest Predictions \n",
    "print(\"------Random Forest Model With n_estimators = 50, and max_depth = 8---------\")\n",
    "print(\"Accuracy Score: \" + str(accuracy_score(val_y_hat, val_data_y)))\n",
    "print(\"F1 Score: \" + str(f1_score(val_y_hat, val_data_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score (F1 Macro for K-Fold): [0.89276626 0.88849037 0.89084706 0.89205283 0.8921951 ]\n",
      "Mean Score of The K-Fold CV: 0.8912703213019665\n"
     ]
    }
   ],
   "source": [
    "# Make and View Predictions with the K-fold Model \n",
    "val_k_fold_scores = cross_val_score(mod, val_x_pp, val_data_y, scoring='f1_macro', cv=k_fold)\n",
    "print('CV Score (F1 Macro for K-Fold): ' + str(val_k_fold_scores))\n",
    "print(\"Mean Score of The K-Fold CV: \" + str(val_k_fold_scores.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
